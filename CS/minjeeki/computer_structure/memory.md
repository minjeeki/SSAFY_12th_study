# 메모리(RAM)와 캐시 메모리

> RAM의 용량은 컴퓨터 성능에 어떤 영향을 미치는가
> 
> 
> DRAM, SRAM, SDRAM, DDR SDRAM의 특징
> 

## RAM

### RAM은 휘발성 저장장치이다

- 휘발성 저장 장치 : 전원을 끄면 저장된 내용이 사라지는 저장 장치
    
    ⇒ 실행할 대상을 올리는 역할
    
- 비휘발성 저장 장치 : 전원이 꺼져도 저장된 내용이 유지되는 저장 장치
    
    ⇒ SSD, HDD, ROM 등의 보조 기억 장치
    
    ⇒ 보관할 대상을 올리는 역할
    

> CPU는 실행하고 싶은 프로그램이 보조기억장치에 있다면 RAM에 복사해 저장한 뒤 실행함
> 

### RAM의 용량과 성능

- RAM의 역할
    
    : 실행하고 싶은 프로그램을 보조기억장치에서 가져와서 CPU에서 사용할 수 있도록 함
    
- RAM의 용량이 적다면?
    
    보조기억장치에서 실행할 프로그램을 가져오는 일이 잦아 실행 시간이 길어짐
    
- RAM의 용량이 크다면?
    
    보조기억장치에서 많은 데이터를 가져와 미리 RAM에 저장 ⇒ 많은 프로그램 동시 실행 유리
    
    용량이 필요 이상으로 커졌을 때 속도가 비례해서 증가하진 않음
    

### RAM의 종류

> RAM의 종류는 크게 DRAM, SRAM, SDRAM, DDRSDRAM로 나뉨
> 
1. DRAM (Dynamic RAM)
    
    > 우리가 일반적으로 메모리로서 사용하는 RAM
    > 
    
    : 저장된 데이터가 동적으로 변하는(사라지는) RAM ⇒ 시간이 지나면 저장된 데이터가 사라짐
    
    - 단점
        
        : 데이터의 소멸을 막기 위해 일정 주기로 데이터를 재활성화(다시 저장)해야 함
        
    - 장점
        - 소비 전력이 비교적 낮음
        - 저렴함
        - 집적도가 높음 (더 작고 빽빽하게 만들 수 있음)⇒ 대용량 설계 용이함
2. SRAM (Static RAM)
    
    > 캐시 메모리에 사용하는  RAM
    > 
    
    : 저장된 데이터가 변하지 않는 RAM ⇒ 시간이 지나도 저장된 데이터가 사라지지 않음
    
    - 장점
        - 주기적으로 데이터를 재활성화할 필요가 없음
        - DRAM보다 일반적으로 속도가 빠름
    - 단점
        - 집적도가 낮음
        - 소비 전력이 큼
        - 가격이 비쌈
    
    ⇒ 대용량으로 만들 필요는 없지만 속도가 빨라야 하는 저장 장치
    
3. SDRAM (synchronous Dynamic RAM, SDR SDRAM)
    
    : 클럭 신호와 동기화된 (클럭에 맞춰 동작하며 클럭마다 CPU와 정보 교환) 발전된 형태의 DRAM
    
4. DDR SDRAM (Double Data Rate SDRAM)
    
    : 대역폭을 높여 속도를 빠르게 만든 SDRAM
    
    - 대역폭 : 데이터를 주고받는 길의 너비
    
    ⇒ 한 클럭에 주고받는 정보가 SDRAM보다 높음 (전송 속도가 더 빠름)
    
    - DDR2 SDRAM은 DDR SDRAM보다 2배, SDR DRAM보다 4배 더 대역폭이 넓음
        
        DDR3 SDRAM은 DDR2 SDRAM보다 2배, SDR DRAM보다 8배 더 대역폭이 넓음
        
        DDR4 SDRAM은 DDR3 SDRAM보다 2배, SDR DRAM보다 16배 더 대역폭이 넓음
        

## 메모리 주소 공간

- 메모리에 저장된 정보의 위치는 주소로 나뉠 수 있으며, 주소는 사용 주체에 따라 나뉜다.
(물리 주소 - 메모리 하드웨어 / 논리 주소 - CPU, 프로그램)
- CPU와 메모리에 저장되어 실행된 프로그램은 메모리에 적재된 내용물을 모두 알지 못한다
    
    (메모리에 저장된 정보는 시시각각 변하기 때문 / 다른 프로그램의 물리 주소를 알 필요 없음)
    

### 물리주소와 논리주소

- 물리주소
    
    : 메모리 하드웨어가 사용하는 주소 (정보가 실제로 저장된 하드웨어 상의 주소)
    
    - 발생 주체 : 메모리
- 논리 주소
    
    : CPU와 실행 중인 프로그램이 사용하는 주소
    (실행 중인 프로그램 각각에 부여된 0번지로부터 시작되는 주소)
    
    - 발생 주체 : CPU

⇒ CPU가 메모리와 상호작용하려면 논리 주소와 물리 주소 간의 변환이 이뤄져야 한다

### 메모리 관리 장치 (MMU)와 주소 변환

![image.png](/CS/minjeeki/computer_structure/cpu_image/image.png)

- 메모리 관리 장치 (MMU, Memory Management Unit)
    
    : 논리 주소와 물리 주소 간의 변환을 담당하는 하드웨어
    
    - 위치 : CPU와 주소 버스 사이
- 논리 주소 → 물리 주소 변환
    
    : 논리 주소 + 베이스 레지스터 값
    
    - 베이스 레지스터 : 프로그램의 첫 물리 주소를 저장하는 레지스터
    - 논리주소 : 프로그램의 시작점(베이스 레지스터 저장값)으로부터 떨어진 거리

### 메모리 보호 기법 (feat. 한계 레지스터)

> 프로그램의 논리 주소 영역을 벗어난, 다른 프로그램 영역의 명령어는 실행되면 안된다.
> 
- 한계 레지스터
    
    : 논리 주소 범위를 벗어나는 명령어 실행을 방지하고 실행 중인 프로그램이 다른 프로그램에 영향 받지 않도록 보호하는 역할을 하는 레지스터
    
    - 논리 주소의 최대 크기를 저장함
    - 범위를 벗어난 영역 접근을 시도할 경우 인터럽트 (트랩)을 발생 → 실행 중단
- 물리 주소 범위
    
    (베이스 레지스터 값) ≤ (물리 주소 범위) ≤ (베이스 레지스터 값 + 한계 레지스터 값 미만)
    

## 캐시 메모리

> CPU의 연산 속도 대비 느린 메모리의 접근 시간에 대한 문제를 해결하기 위한 저장 장치
> 
- 저장 장치의 일반적인 명제
    
    > 빠르고 용량이 큰 저장 장치는 존재하기 어렵다
    > 
    - CPU에 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다
    - 속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다
    
    ⇒ 낮은 가격대의 대용량 저장 장치를 원한다면 느린 속도를 감수해야 한다
    
    ⇒ 빠른 메모리를 원한다면 작은 용량과 비싼 가격을 감수해야 한다
    

### 저장 장치 계층 구조 (memory hierarchy, 메모리 계층 구조)

: CPU에 얼마나 가까운가를 기준으로 저장 장치들을 계층적으로 나타낸 것

![image.png](/CS/minjeeki/computer_structure/memory_img/image%201.png)

- CPU는 프로그램을 실행하는 과정에서 메모리에 빈번하게 접근해야 하지만,
CPU가 메모리에 접근하는 속도는 CPU가 레지스터에 접근하는 속도보다 느리다
    
    ⇒ CPU의 연산 속도와의 격차를 줄일 수 있는, 메모리의 접근 속도를 빠르게 하는 방법은?
    
- cf. 디스크 캐시 : 주기억장치와 보조기억장치 사이에 존재하는 캐시

### 캐시 메모리 (cache memory)

: CPU와 메모리 사이에 위치하고 레지스터보다 용량이 크고 메모리보다 속도가 빠른 SRAM 기반 저장 장치

- 등장 배경 : CPU 연산 속도와 메모리 접근 속도의 차이를 줄이기 위해 등장
- 위치
    
    : 일반적으로  L1, L2 캐시는 CPU 코어 내부에, L3는 코어 외부에 있다
    
    ⇒ 멀티 코어 프로세서의 경우 일반적으로 L1, L2는 코어마다 갖고 있으며 L3는 공유함
    

---

- CPU가 사용할 법한 대상을 예측해서 저장한다
- 캐시 메모리는 또한 CPU와 가까운 순서대로 계층을 갖는다
    - L1 캐시, L2 캐시, L3 캐시 (메모리 계층 구조의 특성을 그대로 갖는다)
        - L1 : CPU 내부 (코어 내부)
        - L2 : CPU와 RAM 사이 존재 (코어 내부에 있기도 함)
        - L3 : 메인 보드
- 분리형 캐시 (split cache)
    
    : L1 캐시의 접근 속도를 빠르게 하기 위해 L1 캐시를 L1I과 L1D로 분리
    
    - L1I 캐시 : 명령어만을 저장
    - L1D 캐시 : 데이터만을 저장

### 캐시 히트와 캐시 미트

- 캐시 히트와 캐시 미스
    - 캐시 히트 (Cache hit)
        
        : 캐시의 예측이 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용
        
    - 캐시 미스 (Cache miss)
        
        : 예측이 틀려 메모리(DRAM)에서 데이터를 직접 가져옴
        
        ⇒ 캐시 메모리 이점 활용 X, 성능 저하
        
- 캐시 적중률 (Cache hit ratio)
    
    : 캐시가 히트되는 비율
    
    `캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)`
    
    - 일반적인 컴퓨터의 캐시 적중률 : 85 ~ 95%
- 캐시 미스의 3가지 케이스
    - Cold miss : 해당 메모리 주소를 처음 불러서 나오는 미스
    - Conflict miss
        
        : 캐시 메모리에 A와 B 데이터를 저장해야 하는데 A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 발생하는 미스 ⇒ 주소 할당 문제
        
    - Capacity miss
        
        : 캐시 메모리의 공간이 부족해서 발생하는 미스 ⇒ 공간 문제
        

### 캐시 메모리 작동 원리, ‘참조 지역성의 원리’

- CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리
    1. CPU는 최근 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.
        
        ⇒ 시간 지역성 (temporal locality)
        
        - CPU는 변수가 저장된 메모리 공간을 언제든 다시 참조할 수 있다
        - for이나 while 같은 반복문에서 사용하는 조건 변수처럼 한번 참조된 데이터는 다시 참조될 가능성이 높다
    2. CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.
        
        ⇒ 공간 지역성 (spatial locality)
        
        - CPU가 실행하려는 프로그램은 보통 관련 데이터들끼리 한데 모여있다.
        (하나의 프로그램 내에서도 관련 있는 데이터들은 모여서 저장된다)
        - A[0], A[1]과 같은 연속 접근 시 참조된 데이터 근처에 있는 데이터가 잠시 후 또 다시 사용될 가능성이 높음
    
    ⇒ 캐시에 데이터를 저장할 때는 참조 지역성을 최대한 활용하기 위해 옆 주소의 데이터도 같이 가져온다.
    

### 캐시 메모리 작동 방식

- Direct Mapped Cache
    
    : 가장 기본적인 구조. DRAM의 여러 주소가 캐시 메모리에 한 주소에 대응되는 다대일 방식
    
    - 장점 : 간단, 빠름
    - 단점 : Conflict Miss 발생
- Fully Associative Cache
    
    : 비어있는 캐시 메모리가 있으면, 마음대로 주소를 지정하는 방식
    
    - 장점 : 간단한 저장 방식
    - 단점 : 찾을 때 문제가 발생
        - 조건이나 규칙이 없어서 특정 캐시 Set 안에 있는 모든 블럭을 한번에 찾아 원하는 데이터가 있는지 검색 필요
        - CAM이라는 특수 메모리 구조를 사용해야 하나 가격이 비쌈
- Set Associative Cache
    
    : Direct + Fully 방식
    
    - 특정 행을 지정하고 행 안의 어떤 열이 비어있을 때 저장하는 방식
    - Direct에 비해 검색 속도는 느리나 저장이 빠름
    - Fully에 비해 저장 속도는 느리나 검색이 빠름

## 문제

### 1. RAM의 종류에 대해서 설명해주세요 (SRAM, DRAM의 차이 중점적으로)

### 2. 논리 주소와 물리 주소에 대해서 설명하고, 논리 주소로부터 물리 주소로 변환 과정에 대해서 설명하세요. 논리 주소가 다른 영역에 접근할 경우 어떻게 해결하는지도 설명해주세요.

### 3. 캐시 메모리의 동작 원리에 대해서 설명해주세요.

## Claude 문제와 답

- 주기억장치와 캐시 메모리의 주요 차이점은 무엇인가요?
    
    주기억장치는 CPU가 직접 접근할 수 있는 대용량 저장소로, 보통 RAM을 의미합니다. 반면 캐시 메모리는 CPU와 주기억장치 사이에 위치한 소용량의 고속 메모리로, 자주 사용되는 데이터를 저장하여 접근 속도를 높입니다. 캐시는 주기억장치보다 빠르지만 용량이 작고 비용이 높습니다.
    
- 캐시 메모리가 시스템 성능 향상에 어떤 역할을 하는지 설명해주세요.
    
    캐시 메모리는 자주 사용되는 데이터를 고속의 메모리에 저장함으로써 CPU가 주기억장치에 접근하는 횟수를 줄입니다. 이로 인해 데이터 접근 시간이 단축되어 전체적인 시스템 성능이 향상됩니다. 특히 지역성 원리를 활용하여 효율적으로 작동합니다.
    
- 캐시 일관성(Cache Coherence) 문제란 무엇이며, 어떻게 해결할 수 있나요?
    
    캐시 일관성 문제는 멀티프로세서 시스템에서 여러 캐시가 동일한 메모리 위치의 데이터 사본을 가질 때 발생합니다. 한 프로세서가 자신의 캐시에 있는 데이터를 수정할 경우, 다른 캐시들의 데이터가 오래된 상태가 될 수 있습니다. 이를 해결하기 위해 MESI 프로토콜과 같은 캐시 일관성 프로토콜을 사용하여 모든 캐시의 데이터를 동기화합니다.
    
- 캐시 메모리의 지역성(Locality) 원리에 대해 설명해주시고, 시간 지역성과 공간 지역성의 차이점을 말씀해주세요.
    
    지역성 원리는 프로그램이 모든 메모리 영역을 균일하게 접근하지 않고, 특정 영역을 집중적으로 참조한다는 개념입니다. 시간 지역성은 최근에 참조된 데이터가 가까운 미래에 다시 참조될 가능성이 높다는 것을 의미하며, 공간 지역성은 특정 데이터 주변의 데이터들이 연속적으로 접근될 가능성이 높다는 것을 의미합니다.
    
- 멀티 레벨 캐시 구조에 대해 설명해주시고, 각 레벨의 특징을 간략히 말씀해주세요.
    
    멀티 레벨 캐시 구조는 여러 단계의 캐시를 사용하여 성능을 최적화하는 방식입니다. 일반적으로 L1, L2, L3 캐시로 구성됩니다. L1 캐시는 CPU에 가장 가까우며 가장 빠르지만 용량이 작습니다. L2 캐시는 L1보다 크고 느리며, L3 캐시는 가장 크지만 가장 느립니다. 이 구조는 속도와 용량 사이의 균형을 맞추어 전체 시스템 성능을 향상시킵니다.
    
- 주기억장치의 종류인 SRAM과 DRAM의 차이점을 설명해주세요.
    
    SRAM(Static RAM)은 전원이 공급되는 동안 데이터를 유지하며, 빠르지만 비용이 높고 집적도가 낮습니다. 주로 캐시 메모리로 사용됩니다. DRAM(Dynamic RAM)은 주기적으로 재충전이 필요하며, SRAM보다 느리지만 저렴하고 집적도가 높아 주기억장치로 주로 사용됩니다.
    
- 캐시 매핑 방식 중 직접 매핑, 완전 연관 매핑, 집합 연관 매핑에 대해 각각의 장단점을 비교해주세요.
    - 직접 매핑: 각 메모리 블록이 캐시의 특정 위치에만 매핑됩니다. 구현이 간단하지만 충돌이 자주 발생할 수 있습니다.
    - 완전 연관 매핑: 메모리 블록이 캐시의 어느 위치에나 저장될 수 있습니다. 충돌이 적지만 검색 시간이 길고 하드웨어 구현이 복잡합니다.
    - 집합 연관 매핑: 직접 매핑과 완전 연관 매핑의 절충안으로, 캐시를 여러 집합으로 나누어 각 집합 내에서 완전 연관 매핑을 사용합니다. 충돌을 줄이면서도 적절한 성능을 제공합니다
- 캐시 교체 정책(Cache Replacement Policy)의 종류와 각각의 특징에 대해 설명해주세요.
    - LRU(Least Recently Used): 가장 오래 사용되지 않은 항목을 교체합니다. 시간 지역성을 잘 활용하지만 구현이 복잡할 수 있습니다.
    - FIFO(First In First Out): 가장 먼저 들어온 항목을 교체합니다. 구현이 간단하지만 성능이 떨어질 수 있습니다.
    - LFU(Least Frequently Used): 사용 빈도가 가장 낮은 항목을 교체합니다. 자주 사용되는 항목을 잘 유지하지만, 최근성을 고려하지 않습니다.
    - Random: 무작위로 항목을 선택하여 교체합니다. 구현이 매우 간단하며, 때로는 다른 정책과 비슷한 성능을 보일 수 있습니다.